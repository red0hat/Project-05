{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/build_model.png\" width=\"600pX2\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Data\n",
    "\n",
    "This is the third step in exploring feature selection on a dataset with many2 features, most of which are not relevant.  The dataset is the synthetic madelon data set from the previous steps.  \n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "A simple logistic regresison on all features was not effective. Applying a 'l1' penalty2 to the logistic regression did not improve the model.  Very2 few features were dropped when the penalty was added.  Clearly, other methods of feature selection need to be exlored.\n",
    "\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "Better selection models need to be used.  Kbest and K nearest neighbors will be used, and any other models that seem effective.\n",
    "\n",
    "### Metric\n",
    "\n",
    "The metric from step 1 will be reused.  It is the mean accuracy of the prediction.  At least 2 test/train splits will be done.  First with the same random state as the previous step then with a new random state.  \n",
    "\n",
    "### Benchmark \n",
    "\n",
    "The primary benchmark is improving the predictive power of the model beyond 50% accuracy.  \n",
    "\n",
    "We know there are 20 salient features.  A secondary benchmark would be selecting less than 20 relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Implement the following code pipeline using the functions you write in `lib/project_5.py`.\n",
    "\n",
    "Start with kBest selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from os import chdir, getcwd;\n",
    "#chdir('lib')\n",
    "from  lib.project_5 import load_data_from_database, make_data_dict, general_transformer, general_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_490</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>466</td>\n",
       "      <td>467</td>\n",
       "      <td>484</td>\n",
       "      <td>491</td>\n",
       "      <td>549</td>\n",
       "      <td>476</td>\n",
       "      <td>488</td>\n",
       "      <td>478</td>\n",
       "      <td>484</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>471</td>\n",
       "      <td>481</td>\n",
       "      <td>509</td>\n",
       "      <td>436</td>\n",
       "      <td>493</td>\n",
       "      <td>661</td>\n",
       "      <td>476</td>\n",
       "      <td>489</td>\n",
       "      <td>514</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>479</td>\n",
       "      <td>474</td>\n",
       "      <td>489</td>\n",
       "      <td>476</td>\n",
       "      <td>495</td>\n",
       "      <td>477</td>\n",
       "      <td>517</td>\n",
       "      <td>481</td>\n",
       "      <td>...</td>\n",
       "      <td>470</td>\n",
       "      <td>471</td>\n",
       "      <td>519</td>\n",
       "      <td>345</td>\n",
       "      <td>482</td>\n",
       "      <td>441</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>571</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>484</td>\n",
       "      <td>460</td>\n",
       "      <td>549</td>\n",
       "      <td>497</td>\n",
       "      <td>461</td>\n",
       "      <td>470</td>\n",
       "      <td>540</td>\n",
       "      <td>477</td>\n",
       "      <td>490</td>\n",
       "      <td>481</td>\n",
       "      <td>...</td>\n",
       "      <td>527</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>745</td>\n",
       "      <td>498</td>\n",
       "      <td>520</td>\n",
       "      <td>484</td>\n",
       "      <td>475</td>\n",
       "      <td>531</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>479</td>\n",
       "      <td>472</td>\n",
       "      <td>445</td>\n",
       "      <td>466</td>\n",
       "      <td>476</td>\n",
       "      <td>474</td>\n",
       "      <td>498</td>\n",
       "      <td>475</td>\n",
       "      <td>483</td>\n",
       "      <td>482</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>474</td>\n",
       "      <td>513</td>\n",
       "      <td>421</td>\n",
       "      <td>483</td>\n",
       "      <td>509</td>\n",
       "      <td>481</td>\n",
       "      <td>490</td>\n",
       "      <td>537</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>481</td>\n",
       "      <td>475</td>\n",
       "      <td>542</td>\n",
       "      <td>481</td>\n",
       "      <td>435</td>\n",
       "      <td>473</td>\n",
       "      <td>467</td>\n",
       "      <td>478</td>\n",
       "      <td>484</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>474</td>\n",
       "      <td>477</td>\n",
       "      <td>388</td>\n",
       "      <td>408</td>\n",
       "      <td>494</td>\n",
       "      <td>484</td>\n",
       "      <td>459</td>\n",
       "      <td>474</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       "1179       466       467       484       491       549       476       488   \n",
       "1529       482       494       479       474       489       476       495   \n",
       "1125       484       460       549       497       461       470       540   \n",
       "1739       479       472       445       466       476       474       498   \n",
       "1303       481       475       542       481       435       473       467   \n",
       "\n",
       "      feat_007  feat_008  feat_009    ...     feat_490  feat_491  feat_492  \\\n",
       "1179       478       484       475    ...          471       481       509   \n",
       "1529       477       517       481    ...          470       471       519   \n",
       "1125       477       490       481    ...          527       480       491   \n",
       "1739       475       483       482    ...          481       474       513   \n",
       "1303       478       484       476    ...          488       474       477   \n",
       "\n",
       "      feat_493  feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  \n",
       "1179       436       493       661       476       489       514       458  \n",
       "1529       345       482       441       486       483       571       514  \n",
       "1125       745       498       520       484       475       531       477  \n",
       "1739       421       483       509       481       490       537       445  \n",
       "1303       388       408       494       484       459       474       495  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'user_name' : \"dsi_student\", \n",
    "          'password' : \"correct horse battery staple\",\n",
    "          'url': 'joshuacook.me',\n",
    "          'port' : \"5432\", \n",
    "          'database' : \"dsi\", \n",
    "          'table' : \"madelon\"}\n",
    "\n",
    "madelon_df = load_data_from_database(**params)\n",
    "madelon_df.drop('index', axis =1, inplace=True)\n",
    "\n",
    "y = madelon_df['label']\n",
    "X = madelon_df.drop('label', axis =1)\n",
    "\n",
    "baseline = make_data_dict(X,y,random_state=33)\n",
    "baseline[0]['X_train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "\n",
      "The mean accuracy of the training set is 67.67%.\n",
      "The mean accuracy of the test set is 54.60%.\n"
     ]
    }
   ],
   "source": [
    "y = madelon_df['label']\n",
    "X = madelon_df.drop('label', axis =1)\n",
    "\n",
    "model = make_data_dict(X,y,random_state=43)\n",
    "\n",
    "X_train = model[-1]['X_train']\n",
    "y_train = model[-1]['y_train']\n",
    "X_test = model[-1]['X_test']\n",
    "y_test = model[-1]['y_test']\n",
    "\n",
    "scale = StandardScaler()\n",
    "baseline.append(general_transformer(scale, X_train, y_train, X_test, y_test))\n",
    "\n",
    "X_train = model[-1]['X_train']\n",
    "y_train = model[-1]['y_train']\n",
    "X_test = model[-1]['X_test']\n",
    "y_test = model[-1]['y_test']\n",
    "\n",
    "kbest = SelectKBest(k=50)\n",
    "model.append(general_transformer(kbest, X_train, y_train, X_test, y_test))\n",
    "\n",
    "X_train = model[-1]['X_train']\n",
    "y_train = model[-1]['y_train']\n",
    "X_test = model[-1]['X_test']\n",
    "y_test = model[-1]['y_test']\n",
    "\n",
    "LogReg =LogisticRegression(n_jobs=-1,verbose =2)\n",
    "model.append(general_model(LogReg,X_train, y_train, X_test, y_test))\n",
    "print \"\\n\"\n",
    "print \"The mean accuracy of the training set is {:.2f}%.\".format (model[-1]['train_score']*100)\n",
    "print \"The mean accuracy of the test set is {:.2f}%.\".format (model[-1]['test_score']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a significant improvement.  Moving on to gridsearch, with cross validation.  The model is reaching the maX2 number of iterations.  Perhaps maX2 iterations needs to be increased as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]\n",
      "\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=200, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=2, warm_start=False)\n",
      "The mean accuracy of the training set is 60.80%.\n",
      "The mean accuracy of the test set is 61.20%.\n"
     ]
    }
   ],
   "source": [
    "y2 = madelon_df['label']\n",
    "X2 = madelon_df.drop('label', axis =1)\n",
    "\n",
    "model2 = make_data_dict(X2,y2,random_state=43)\n",
    "\n",
    "X2_train = model2[-1]['X_train']\n",
    "y2_train = model2[-1]['y_train']\n",
    "X2_test = model2[-1]['X_test']\n",
    "y2_test = model2[-1]['y_test']\n",
    "\n",
    "scale = StandardScaler()\n",
    "baseline.append(general_transformer(scale, X2_train, y2_train, X2_test, y2_test))\n",
    "\n",
    "X2_train = model2[-1]['X_train']\n",
    "y2_train = model2[-1]['y_train']\n",
    "X2_test = model2[-1]['X_test']\n",
    "y2_test = model2[-1]['y_test']\n",
    "\n",
    "kbest = SelectKBest(k=10)\n",
    "model2.append(general_transformer(kbest, X2_train, y2_train, X2_test, y2_test))\n",
    "\n",
    "X2_train = model2[-1]['X_train']\n",
    "y2_train = model2[-1]['y_train']\n",
    "X2_test = model2[-1]['X_test']\n",
    "y2_test = model2[-1]['y_test']\n",
    "\n",
    "param_grid = param_grid = {'C': [10**i for i in range(-3, 3)] , 'penalty' : ['l1','l2']}\n",
    "grid = GridSearchCV(LogisticRegression(verbose =2,max_iter=200, n_jobs=-1), param_grid)\n",
    "\n",
    "model2.append(general_model(grid,X2_train, y2_train, X2_test, y2_test))\n",
    "\n",
    "print \"\\n\"\n",
    "print model2[-1]['model'].best_estimator_\n",
    "print \"The mean accuracy of the training set is {:.2f}%.\".format (model2[-1]['train_score']*100)\n",
    "print \"The mean accuracy of the test set is {:.2f}%.\".format (model2[-1]['test_score']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best version using KBest selector, there is a slight improvement in accuracy for the test set.  The best estimator uses C = 0.01 and the 'l1' penalty.\n",
    "\n",
    "Perhaps the K Nearest Nieghbors will be more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kbest = 6\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=9, p=3,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 76.93%.\n",
      "The mean accuracy of the test set is 71.80%.\n",
      "kbest = 8\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 90.07%.\n",
      "The mean accuracy of the test set is 81.40%.\n",
      "kbest = 10\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 92.93%.\n",
      "The mean accuracy of the test set is 88.20%.\n",
      "kbest = 12\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 90.40%.\n",
      "The mean accuracy of the test set is 88.20%.\n",
      "kbest = 14\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 92.53%.\n",
      "The mean accuracy of the test set is 88.20%.\n",
      "kbest = 16\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 91.07%.\n",
      "The mean accuracy of the test set is 87.60%.\n",
      "kbest = 18\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "The mean accuracy of the training set is 92.13%.\n",
      "The mean accuracy of the test set is 87.00%.\n"
     ]
    }
   ],
   "source": [
    "for k in range (6,20,2):\n",
    "    y3 = madelon_df['label']\n",
    "    X3 = madelon_df.drop('label', axis =1)\n",
    "\n",
    "    model3 = make_data_dict(X3,y3,random_state=43)\n",
    "\n",
    "    X3_train = model3[-1]['X_train']\n",
    "    y3_train = model3[-1]['y_train']\n",
    "    X3_test = model3[-1]['X_test']\n",
    "    y3_test = model3[-1]['y_test']\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    baseline.append(general_transformer(scale, X3_train, y3_train, X3_test, y3_test))\n",
    "\n",
    "    X3_train = model3[-1]['X_train']\n",
    "    y3_train = model3[-1]['y_train']\n",
    "    X3_test = model3[-1]['X_test']\n",
    "    y3_test = model3[-1]['y_test']\n",
    "\n",
    "\n",
    "    kbest = SelectKBest(k=k)\n",
    "    model3.append(general_transformer(kbest, X3_train, y3_train, X3_test, y3_test))\n",
    "\n",
    "    X3_train = model3[-1]['X_train']\n",
    "    y3_train = model3[-1]['y_train']\n",
    "    X3_test = model3[-1]['X_test']\n",
    "    y3_test = model3[-1]['y_test']\n",
    "\n",
    "\n",
    "    param_grid = param_grid = {'n_neighbors': [i for i in range(3, 22 ,2)] , 'p' : [2,3]}\n",
    "    grid = GridSearchCV(KNeighborsClassifier(n_jobs=-1), param_grid)\n",
    "\n",
    "    model3.append(general_model(grid,X3_train, y3_train, X3_test, y3_test))\n",
    "\n",
    "    print \"kbest = {}\".format(k)\n",
    "    print model3[-1]['model'].best_estimator_\n",
    "    print \"The mean accuracy of the training set is {:.2f}%.\".format (model3[-1]['train_score']*100)\n",
    "    print \"The mean accuracy of the test set is {:.2f}%.\".format (model3[-1]['test_score']*100)\n",
    "\n",
    "model3.append(general_model(grid,X3_train, y3_train, X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model, so far, uses the kbest transformer to select the 14 best features, then K nearest neighbors model is used with neighbors = 3 and p =2.  The 'p' parameter is the power for the minkowski metric; p=2 is the same as the euclidean distance.\n",
    "\n",
    "Let's rerun the best model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy of the training set is 92.53%.\n",
      "The mean accuracy of the test set is 88.20%.\n"
     ]
    }
   ],
   "source": [
    "y4 = madelon_df['label']\n",
    "X4 = madelon_df.drop('label', axis =1)\n",
    "\n",
    "model4 = make_data_dict(X4,y4,random_state=43)\n",
    "\n",
    "X4_train = model4[-1]['X_train']\n",
    "y4_train = model4[-1]['y_train']\n",
    "X4_test = model4[-1]['X_test']\n",
    "y4_test = model4[-1]['y_test']\n",
    "\n",
    "scale = StandardScaler()\n",
    "baseline.append(general_transformer(scale, X4_train, y4_train, X4_test, y4_test))\n",
    "\n",
    "X4_train = model4[-1]['X_train']\n",
    "y4_train = model4[-1]['y_train']\n",
    "X4_test = model4[-1]['X_test']\n",
    "y4_test = model4[-1]['y_test']\n",
    "\n",
    "\n",
    "kbest = SelectKBest(k=14)\n",
    "model4.append(general_transformer(kbest, X4_train, y4_train, X4_test, y4_test))\n",
    "\n",
    "X4_train = model4[-1]['X_train']\n",
    "y4_train = model4[-1]['y_train']\n",
    "X4_test = model4[-1]['X_test']\n",
    "y4_test = model4[-1]['y_test']\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1, p=2, n_neighbors=3)\n",
    "\n",
    "model4.append(general_model(knn,\n",
    "                            X4_train, \n",
    "                            y4_train,\n",
    "                            X4_test, \n",
    "                            y4_test))\n",
    "\n",
    "print \"The mean accuracy of the training set is {:.2f}%.\".format (model4[-1]['train_score']*100)\n",
    "print \"The mean accuracy of the test set is {:.2f}%.\".format (model4[-1]['test_score']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_048', 'feat_064', 'feat_105', 'feat_128', 'feat_241', 'feat_277', 'feat_336', 'feat_338', 'feat_378', 'feat_442', 'feat_453', 'feat_472', 'feat_475', 'feat_493']\n"
     ]
    }
   ],
   "source": [
    "good_feature_from_final_model =  [y for x,y in zip(kbest.get_support(),X4.columns) if x]\n",
    "print good_feature_from_final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Automatic feature selection is viable for filtering for salient features and making a useful model.  The current model has room for improvement.  Too many features were selected, and the accuracy has room for improvment. Other models may provide better feature selection.  Also, this model should be tested against new datasets to test if it can be generalized.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
